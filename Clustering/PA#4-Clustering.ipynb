{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment # 4 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When submitting, fill your full name, your student ID and your NetID in this cell. Note that this is a markdown cell! \n",
    "\n",
    "Student Full Name:\n",
    "\n",
    "ID:\n",
    "\n",
    "Team Mate name :\n",
    "\n",
    "ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Work is to be done in a team\n",
    "2. Any cheating including plagiarism, cooperation will be reported to the corresponding UTA’ s instance.\n",
    "3. If using any resource (books, internet), please make sure that you cite it.\n",
    "4. Follow the given structure. Specifically, place all your tasks in THIS NOTEBOOK BUT IN SEPARATE BLOCKS. Then save this notebook as 'yourNetID_pa4.ipynb' and submit it. [-5 : if not followed.] \n",
    "5. Do not alter the dataset name.\n",
    "6. Please dont ask any details specific to the project like \"How to plot XYZ ? What parameters are to be used? \" and so on..\n",
    "7. Report is not required for this assignment. If you want to document a function or a process, just comment or use markup cell.\n",
    "8. Please dont send images of your visualizations to verify whether they are right or not before submission deadline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>The dataset is about the \"Credit Card Segmentation\". Your primary goal is to provide a segmentation strategy for launching a marketing campaign which helps a company to segregate customers into relevant groups. This will help the marketing team to explore more with sales strategy and increase the conversion rates. The dataset explains the behavior of customer actively using credit cards spanning 6 months. It has about 8950 users and has 18 behavioral variable columns.</b>\n",
    "\n",
    "Use \"bank.csv\" attached in the same directory with this ipynb file.\n",
    "\n",
    "\n",
    "**** The Dataset details are as follows:\n",
    "\n",
    "* CUST_ID : Identification of Credit Card holder (Categorical)\n",
    "\n",
    "* BALANCE : Balance amount left in their account to make purchases (\n",
    "\n",
    "* BALANCE_FREQUENCY : How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)\n",
    "\n",
    "* PURCHASES : Amount of purchases made from account\n",
    "\n",
    "* ONEOFF_PURCHASES : Maximum purchase amount done in one-go\n",
    "\n",
    "* INSTALLMENTS_PURCHASES : Amount of purchase done in installment\n",
    "\n",
    "* CASH_ADVANCE : Cash in advance given by the user\n",
    "\n",
    "* PURCHASES_FREQUENCY : How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)\n",
    "\n",
    "* ONEOFFPURCHASESFREQUENCY : How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)\n",
    "\n",
    "* PURCHASESINSTALLMENTSFREQUENCY : How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)\n",
    "\n",
    "* CASHADVANCEFREQUENCY : How frequently the cash in advance being paid\n",
    "\n",
    "* CASHADVANCETRX : Number of Transactions made with \"Cash in Advanced\"\n",
    "\n",
    "* PURCHASES_TRX : Numbe of purchase transactions made\n",
    "\n",
    "* CREDIT_LIMIT : Limit of Credit Card for user\n",
    "\n",
    "* PAYMENTS : Amount of Payment done by user\n",
    "\n",
    "* MINIMUM_PAYMENTS : Minimum amount of payments made by user\n",
    "\n",
    "* PRCFULLPAYMENT : Percent of full payment paid by user\n",
    "\n",
    "* TENURE : Tenure of credit card service for user\n",
    "\n",
    "\n",
    "The unsupervised problem is how to segregate the data.\n",
    "\n",
    "You need to submit this ipynb file in a zipped folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Python Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Python packages here\n",
    "#Seaborn,numpy,pandas,sklearn,matplotlib only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 0 : Preprocessing\n",
    "\n",
    "#### Preprocessing will be needed for the data as some of the data might be empty or null and needs to be quantified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do your pre-processing here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1-a: Determine “k” value from the elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will be using the elbow method to determine the optimal number of clusters for k-means clustering.\n",
    "\n",
    "We need some way to determine whether we are using the right number of clusters when using k-means clustering. One method to validate the number of clusters is the elbow method. \n",
    "\n",
    "The idea of the elbow method is to run k-means clustering on the dataset for a range of values of k , and for each value of k calculate the sum of squared errors (SSE). Then, plot a line chart of the SSE for each value of k. If the line chart looks like an arm, then the \"elbow\" on the arm is the value of k that is the best. The idea is that we want a small SSE, but that the SSE tends to decrease toward 0 as we increase k (the SSE is 0 when k is equal to the number of data points in the dataset, because then each data point is a cluster, and there is no error between it and the center of its cluster). So our goal is to choose a small value of k that still has a low SSE, and the elbow usually represents where we start to have diminishing returns by increasing k.\n",
    "\n",
    "For this task, you need to perform the elbow method for k from 1 to 20 and plot a line chart of the SSE for each value of k, and determine the best k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########################begin code for Task 1-a\n",
    "#########################begin code for Task 1-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1-b: Visualization for K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will be performing k-means clustering for k=8 and k=4 and visualize the predicted sample on scatter plots. Perform kmeans for clustering samples in your predicted set. \n",
    "\n",
    "The key here is to use metrics to understand which one of them K values gives you the best score.\n",
    "\n",
    "Since your dataset has multiple features(dimensions), you won't be able to plot your data on a scatter plot. Thus, you’re going to visualize your data with the help of one of the Dimensionality Reduction techniques, namely Principal Component Analysis (PCA). The idea in PCA is to find a linear combination of the two variables that contains most of the information. This new variable or “principal component” can replace the two original variables. You can easily apply PCA to your data with the help of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "###################begin code for Task 1-b-1: Visualize the predicted labels with clusters = 4\n",
    "\n",
    "# Create the KMeans model\n",
    "\n",
    "# Compute cluster centers and predict cluster index for each sample \n",
    "\n",
    "# Model and fit the data to the PCA model\n",
    "\n",
    "# Visualize the predicted labels.\n",
    "\n",
    "\n",
    "###################end code for Task 1-b-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 1-b-2: Visualize the predicted  labels with clusters = 8\n",
    "\n",
    "# Create the KMeans model\n",
    "\n",
    "# Compute cluster centers and predict cluster index for each sample \n",
    "\n",
    "# Model and fit the data to the PCA model\n",
    "\n",
    "# Visualize the predicted labels.\n",
    "\n",
    "\n",
    "###################end code for Task 1-b-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you need to provide the evaluation of your clustering model. Print out a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 1-b-3: Print out a confusion matrix of the input dataset with clusters = 4\n",
    "\n",
    "\n",
    "###################end code for Task 1-b-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 1-b-4: Print out a confusion matrix of the input dataset with clusters =8\n",
    "\n",
    "\n",
    "###################end code for Task 1-b-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: Hierarchical Agglomerative  Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2-a: Find the best Hierarchical Agglomerative Clustering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will be performing Hierarchical Agglomerative clustering with different linkage methods (complete and average) and different similarity measures (cosine, euclidean, and manhattan) in order to find the best pair of linkage method and similarity measure. Use F1 score for evaluation and take n_clusters = 8 and n_clusters = 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 2-a: Print out a confusion matrix\n",
    "# Import AgglomerativeClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# Import pairwise_distances for calculating pairwise distance matrix\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "# Import f1_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "## Calculate pairwise distance matrix.\n",
    "pdm = None\n",
    "\n",
    "## Model and fit the data to the AgglomerativeClustering model\n",
    "## complete linkage + cosine\n",
    "\n",
    "\n",
    "## Model and fit the data to the AgglomerativeClustering model\n",
    "## complete linkage + euclidean\n",
    "\n",
    "\n",
    "## Model and fit the data to the AgglomerativeClustering model\n",
    "## complete linkage + manhattan\n",
    "\n",
    "\n",
    "## Model and fit the data to the AgglomerativeClustering model\n",
    "## average linkage + cosine\n",
    "\n",
    "\n",
    "## Model and fit the data to the AgglomerativeClustering model\n",
    "## average linkage + euclidean\n",
    "\n",
    "\n",
    "## Model and fit the data to the AgglomerativeClustering model\n",
    "## average linkage + manhattan\n",
    "\n",
    "\n",
    "print(\"F1-score for complete linkage + cosine\", None)\n",
    "print(\"F1-score for complete linkage + euclidean\", None)\n",
    "print(\"F1-score for complete linkage + manhattan\", None)\n",
    "print(\"F1-score for average linkage + cosine\", None)\n",
    "print(\"F1-score for average linkage + euclidean\", None)\n",
    "print(\"F1-score for average linkage + manhattan\", None)\n",
    "\n",
    "###################end code for Task 2-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2-b:  Visualization for Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best performed model from the previous step and use that model for visualizing the predicted  samples on scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 2-b: Visualize the predicted labels \n",
    "\n",
    "\n",
    "# Visualize the predicted  labels.\n",
    "\n",
    "\n",
    "###################end code for Task 2-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3:  WEKA Visualization of K-means Clustering and Hierarchical Agglomerative Clustering\n",
    "\n",
    "#### Provide the WEKA files inside a titled folder, and attach all the required files for what you think might be relevant for explaining. Each of the image you attach, attach a two line description below here, For example (image1.png - \"Writer your description here.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3-a : Visualize the k-means clustering using weka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################start Task 3-a\n",
    "\n",
    "\n",
    "\n",
    "###################end Task 3-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3-b : Visualize the hierarchical clustering using weka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################start Task 3-b\n",
    "\n",
    "\n",
    "\n",
    "###################end Task 3-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# TASK 4:  Compare K-Means Clustering and Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4-a: Visualize Clusters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, Visualize the predicted labels from k-means clustering and agglomerative clustering(best one from task 2-a). Basically, you need to plot two scatter plots as subplots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 4-a: Visualize the predicted labels\n",
    "\n",
    "### Visualize Kmeans Clustering.\n",
    "\n",
    "\n",
    "### Visualize Agglomerative Clustering.\n",
    "\n",
    "\n",
    "## The plots has to have all the labels, and the figures should be descriptive of what is being presented.\n",
    "\n",
    "###################end code for Task 4-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4-b: Compare K-Means Clustering &  Hierarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out confusion matrices for kmeans and agglomerative clustering. Also, compare precision, recall, and F1-score for both model. \n",
    "\n",
    "Type your reasoning for which one of the clustering models is best fit for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################begin code for Task 4-b\n",
    "\n",
    "## Confusion Matrix for Kmeans.\n",
    "\n",
    "## Confusion Matrix for Hierarchial Agglomerative Clustering.\n",
    "\n",
    "## Compare precision, recall, and F1-score for both model.\n",
    "\n",
    "## Which model is the best fit for our dataset. Explain in detail!\n",
    "\n",
    "###################end code for Task 4-b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Follow the Rules</b> \n",
    "\n",
    "<b>[5 points] Task0:</b>  \n",
    "\n",
    "    [05 points] Task 0: 5 points\n",
    "\n",
    "\n",
    "<b>[30 points] Task 1:</b>  \n",
    "\n",
    "    [05 points] Task 1-a: 15 points\n",
    "\n",
    "    [20 points] Task 1-b: 15 points\n",
    "\n",
    "\n",
    "<b>[30 points] Task 2:</b>  \n",
    "\n",
    "    [20 points] Task 2-a: 15 points\n",
    "    \n",
    "    [10 points] Task 2-b: 15 points\n",
    "\n",
    "<b>[10 points] Task 3:</b> \n",
    "\n",
    "    Task 3-a: 5 points\n",
    "\n",
    "    Task 3-b: 5 points\n",
    "\n",
    "<b>[25 points] Task 4:</b> \n",
    "\n",
    "    Task 4-a: 10 points\n",
    "\n",
    "    Task 4-b: 15 points"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
